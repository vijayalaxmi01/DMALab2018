{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough of Data Science - Traveler\n",
    "\n",
    "### * Goal: Predict the country that users will make their first booking in, based on some basic user profile data.\n",
    "\n",
    "#### * Training data, set of users with correct category (i.e. what country they made their first booking in).\n",
    "\n",
    "#### * Build a model to accurately predict the country of first booking.\n",
    "\n",
    "#### * Test data, set of users without the knowledge of outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough process\n",
    "\n",
    "#### [1] Pre-processing: Assessing and analyzing data, cleaning, transforming and adding new features\n",
    "#### [2] Learning model: Constructing and testing learning model\n",
    "#### [3] Post-processing: Creating final predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB 1 CODE - DATA PREPROCESSING (Data Cleaning and Data Transformation on train and test csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exploring Traveler data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline \n",
    "\n",
    "print(\"Reading data...\")\n",
    "train_file = \"./traveler_dataset/train_users_2.csv\"\n",
    "df_train = pd.read_csv(train_file, header = 0,index_col=None)\n",
    "\n",
    "test_file = \"./traveler_dataset/test_users.csv\"\n",
    "df_test = pd.read_csv(test_file, header = 0,index_col=None)\n",
    "\n",
    "# Combining into one dataset for cleaning\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True, sort=False)\n",
    "print(\"Reading data...completed\")\n",
    "\n",
    "# Fixing date formats in Pandas - to_datetime\n",
    "## Change dates to specific format\n",
    "print(\"Fixing timestamps...\")\n",
    "df_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'], format='%Y-%m-%d')\n",
    "df_all['timestamp_first_active'] = pd.to_datetime(df_all['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "print(\"Fixing timestamps...completed\")\n",
    "\n",
    "## Removing date_first_booking column\n",
    "df_all.drop('date_first_booking', axis = 1, inplace = True)\n",
    "print(\"Droped date_first_booking column...\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## Remove outliers function - [1]\n",
    "def remove_outliers(df, column, min_val, max_val):\n",
    "    col_values = df[column].values\n",
    "    df[column] = np.where(np.logical_or(col_values<=min_val, col_values>=max_val), np.NaN, col_values)\n",
    "    return df\n",
    "\n",
    "## Fixing age column - [2]\n",
    "print(\"Fixing age column...\")\n",
    "df_all = remove_outliers(df = df_all, column = 'age', min_val = 15, max_val = 90)\n",
    "df_all['age'].fillna(-1, inplace = True)\n",
    "print(\"Fixing age column...completed\")\n",
    "\n",
    "# Other column missing value - Fill first_affiliate_tracked column\n",
    "print(\"Filling first_affiliate_tracked column...\")\n",
    "df_all['first_affiliate_tracked'].fillna(-1, inplace=True)\n",
    "print(\"Filling first_affiliate_tracked column...completed\")\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### [2] Data Transformation and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own implementation of One Hot Encoding - Data Transformation\n",
    "def convert_to_binary(df, column_to_convert):\n",
    "    categories = list(df[column_to_convert].drop_duplicates())\n",
    "\n",
    "    for category in categories:\n",
    "        cat_name = str(category).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\"-\", \"\").lower()\n",
    "        col_name = column_to_convert[:5] + '_' + cat_name[:10]\n",
    "        df[col_name] = 0\n",
    "        df.loc[(df[column_to_convert] == category), col_name] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# One Hot Encoding\n",
    "print(\"One Hot Encoding categorical data...\")\n",
    "columns_to_convert = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df_all = convert_to_binary(df=df_all, column_to_convert=column)\n",
    "    df_all.drop(column, axis=1, inplace=True)\n",
    "print(\"One Hot Encoding categorical data...completed\")\n",
    "\n",
    "# Add new date related fields - Creating New Features\n",
    "print(\"Adding new fields...\")\n",
    "df_all['day_account_created'] = df_all['date_account_created'].dt.weekday\n",
    "df_all['month_account_created'] = df_all['date_account_created'].dt.month\n",
    "df_all['quarter_account_created'] = df_all['date_account_created'].dt.quarter\n",
    "df_all['year_account_created'] = df_all['date_account_created'].dt.year\n",
    "df_all['hour_first_active'] = df_all['timestamp_first_active'].dt.hour\n",
    "df_all['day_first_active'] = df_all['timestamp_first_active'].dt.weekday\n",
    "df_all['month_first_active'] = df_all['timestamp_first_active'].dt.month\n",
    "df_all['quarter_first_active'] = df_all['timestamp_first_active'].dt.quarter\n",
    "df_all['year_first_active'] = df_all['timestamp_first_active'].dt.year\n",
    "df_all['created_less_active'] = (df_all['date_account_created'] - df_all['timestamp_first_active']).dt.days\n",
    "print(\"Adding new fields...completed\")\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "print(\"Droping fields...\")\n",
    "columns_to_drop = ['date_account_created', 'timestamp_first_active', 'date_first_booking', 'country_destination']\n",
    "for column in columns_to_drop:\n",
    "    if column in df_all.columns:\n",
    "        df_all.drop(column, axis=1, inplace=True)\n",
    "print(\"Droping fields...completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LAB 2 CODE - DATA PREPROCESSING (Data Cleaning and Data Transformation on sessions csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] Extract the primary and secondary devices for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Loading sessions.csv data\n",
    "print(\"Reading sessions data...\")\n",
    "sessions_file = \"./traveler_dataset/sessions.csv\"\n",
    "df_sessions = pd.read_csv(sessions_file, header = 0,index_col=False)\n",
    "print(\"Reading sessions data...completed\")\n",
    "df_sessions.head()\n",
    "\n",
    "print(\"Determing primary device...\")\n",
    "# Selection of all rows for 'user_id', 'device_type', 'secs_elapsed' using .loc operation\n",
    "sessions_device = df_sessions.loc[:, ['user_id', 'device_type', 'secs_elapsed']]\n",
    "#sessions_device.head(10)\n",
    "# Grouping based on 'user_id', 'device_type' the sum of 'secs_elapsed' \n",
    "aggregated_lvl1 = sessions_device.groupby(['user_id', 'device_type'], as_index=False, sort=False).aggregate(np.sum)\n",
    "#aggregated_lvl1.head(10)\n",
    "# Obtaining the index which is true or false based on first largest device type used by users as matching condition\n",
    "idx = aggregated_lvl1.groupby(['user_id'], sort=False)['secs_elapsed'].transform(max) == aggregated_lvl1['secs_elapsed']\n",
    "#idx.head(10)\n",
    "# Obtaining the rows of first largest device type used by users based on index\n",
    "df_sessions_primary = pd.DataFrame(aggregated_lvl1.loc[idx, ['user_id', 'device_type', 'secs_elapsed']])\n",
    "#df_sessions_primary.head(10)\n",
    "# Rename the attributes and modify in the df_sessions_primary dataframe\n",
    "df_sessions_primary.rename(columns = {'device_type':'primary_device','secs_elapsed':'primary_secs'}, inplace=True)\n",
    "#df_sessions_primary.head(10)\n",
    "# Call user defined One Hot Encoding function\n",
    "df_sessions_primary = convert_to_binary(df=df_sessions_primary, column_to_convert='primary_device')\n",
    "#df_sessions_primary.head(10)\n",
    "# drop the 'primary_device' attribute after one-hot encoding\n",
    "df_sessions_primary.drop('primary_device', axis=1, inplace=True)\n",
    "#df_sessions_primary.head(10)\n",
    "print(\"Determing primary device...completed\")\n",
    "print(\"Determing secondary device...\")\n",
    "# Initially drop the primary device index before selecting the remaining device (eg: secondary device)\n",
    "remaining = aggregated_lvl1.drop(aggregated_lvl1.index[idx])\n",
    "#remaining.head(10)\n",
    "# Obtaining the index which is true or false based on second largest device type used by users as matching condition\n",
    "idx = remaining.groupby(['user_id'], sort=False)['secs_elapsed'].transform(max) == remaining['secs_elapsed']\n",
    "#idx.head(10)\n",
    "# Obtaining the rows of second largest device type used by users based on index\n",
    "df_sessions_secondary = pd.DataFrame(remaining.loc[idx , ['user_id', 'device_type', 'secs_elapsed']])\n",
    "#df_sessions_secondary.head(10)\n",
    "# Rename the attributes and modify in the df_sessions_secondary dataframe\n",
    "df_sessions_secondary.rename(columns = {'device_type':'secondary_device', 'secs_elapsed':'secondary_secs'}, inplace=True)\n",
    "#df_sessions_secondary.head(10)\n",
    "# Call user defined One Hot Encoding function\n",
    "df_sessions_secondary = convert_to_binary(df=df_sessions_secondary, column_to_convert='secondary_device')\n",
    "#df_sessions_secondary.head(10)\n",
    "# drop the 'secondary_device' attribute after one-hot encoding\n",
    "df_sessions_secondary.drop('secondary_device', axis=1, inplace=True)\n",
    "#df_sessions_secondary.head(10)\n",
    "print(\"Determing secondary device...completed\")\n",
    "## Testing ...\n",
    "#df_sessions_secondary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] Determine Counts of Actions attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of value in a column\n",
    "def convert_to_counts(df, id_col, column_to_convert):\n",
    "    #id_list = df[id_col].drop_duplicates()\n",
    "    #print (id_list.head())\n",
    "    #Step1\n",
    "    df_counts = df.loc[:,[id_col, column_to_convert]]  \n",
    "    df_counts['count'] = 1\n",
    "    df_counts = df_counts.groupby(by=[id_col, column_to_convert], as_index=False, sort=False).sum()\n",
    "    print('Step1')\n",
    "    print (df_counts.head())\n",
    "    #Step2\n",
    "    new_df = df_counts.pivot(index=id_col, columns=column_to_convert, values='count') \n",
    "    new_df = new_df.fillna(0)\n",
    "    print ('Step2')\n",
    "    print (new_df.head())\n",
    "\n",
    "    # Rename Columns\n",
    "    categories = list(df[column_to_convert].drop_duplicates())\n",
    "    print('categories')\n",
    "    print (categories)\n",
    "    for category in categories:\n",
    "        cat_name = str(category).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\"-\", \"\").lower()\n",
    "        col_name = column_to_convert + '_' + cat_name\n",
    "        new_df.rename(columns = {category:col_name}, inplace=True)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "# Aggregate and combine actions taken columns\n",
    "print(\"Aggregating actions taken...\")\n",
    "session_actions = df_sessions.loc[:,['user_id', 'action', 'action_type', 'action_detail']]\n",
    "#session_actions = df_sessions.loc[:,['user_id', 'action']]\n",
    "#session_actions.head()\n",
    "#columns_to_convert = ['action']\n",
    "columns_to_convert = ['action', 'action_type', 'action_detail']\n",
    "session_actions = session_actions.fillna('not provided')\n",
    "#session_actions.head()\n",
    "first = True\n",
    "for column in columns_to_convert:\n",
    "    print(\"Converting \" + column + \" attribute...\")\n",
    "    current_data = convert_to_counts(df=session_actions, id_col='user_id', column_to_convert=column)\n",
    "    print(\"Converting \" + column + \" attribute... finished\")\n",
    "# If first loop, current data becomes existing data, otherwise merge existing and current\n",
    "    if first:\n",
    "        first = False\n",
    "        actions_data = current_data\n",
    "    else:\n",
    "        actions_data = pd.concat([actions_data, current_data], axis=1, join='inner')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking...\n",
    "actions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3] Data Integration (combine datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4.1] Merge device datasets\n",
    "print(\"Combining df_primary and df_secondary to device dataframe...\")\n",
    "df_sessions_primary.set_index('user_id', inplace=True)\n",
    "df_sessions_secondary.set_index('user_id', inplace=True)\n",
    "device_data = pd.concat([df_sessions_primary, df_sessions_secondary], axis=1, join=\"outer\", sort=False)\n",
    "print(\"Combining df_primary and df_secondary to device dataframe...finished\")\n",
    "\n",
    "# [4.2] Merge device and actions datasets\n",
    "print(\"Combining device and actions to sessions dataframe...\")\n",
    "combined_results = pd.concat([device_data, actions_data], axis=1, join='outer', sort=False)\n",
    "df_sessions_complete = combined_results.fillna(0)\n",
    "print(\"Combining device and actions to sessions dataframe...finished\")\n",
    "\n",
    "# [4.3] Merge user and session datasets\n",
    "print(\"Combining sessions and users to get final dataframe...\")\n",
    "df_all.set_index('id', inplace=True)\n",
    "df_all = pd.concat([df_all, df_sessions_complete], axis=1, join='inner', sort = False)\n",
    "print(\"Combining sessions and users to get final dataframe...finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's Session: Prepare a learning model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temp variables created to store data\n",
    "df_train1 = df_train\n",
    "df_test1 = df_test\n",
    "df_all1 = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_destination'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone: Creating a learning model\n",
    "\n",
    "##### To predict the first booking destination country for each user based on the preprocessed data from lab-1 and lab-2 sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an Algorithm (most cruseal)\n",
    "\n",
    "### [1] Decision Tree\n",
    "**Biggest problem:** model overfitting\n",
    "\n",
    "**Solution -> parameters setting:** Stop model splitting once the records at a given node gets too small (minimum split) and when a certain number of splits have occurred (maximum depth).\n",
    "\n",
    "The problem is \n",
    "- how do you know how large you should grow the tree? \n",
    "- how do you set the parameters to avoid overfitting but still have an accurate model? \n",
    "\n",
    "Reality is that it is extremely difficult to know how to set the parameters. \n",
    "- Set them too conservatively and the model will lose too much predictive power. \n",
    "- Set them too aggressively and the model will start overfitting the data.\n",
    "\n",
    "**BEST PART** - methods have been found to reduce the risk of overfitting and increase predictive power of decisions trees, to train multiple trees (random forest, boosting)\n",
    "\n",
    "[1] The 'random forest' algorithm constructs a large number of different trees by randomly selecting the features that can be used to build each tree (as opposed to using all the features for each tree).\n",
    "\n",
    "[2] 'Boosting' algorithm which builds trees iteratively such that each tree learns from earlier trees. We focus on very popular 'XGBoost' algorithm.\n",
    "\n",
    "#### [2] Alternative Models\n",
    "##### [2.1] K-Nearest Neighbors\n",
    "Classifies a given object by looking at the classification of the k most similar records and seeing how those records are classified. Also known as lazy learner.\n",
    "##### [2.2] Neural Networks\n",
    "Typicaly consists of three layers: an input layer, a hidden layer (although there can be multiple hidden layers) and an output layer.\n",
    "##### [2.3] Support Vector Machines\n",
    "Classifier which separates classes using kernel trick.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach for creating the model using XGBoost algorithm\n",
    "#### [1.1] k-fold Cross Validation\n",
    "##### Why? \n",
    "- one of the key risks when creating models is the risk of overfitting.\n",
    "- to guard against overfitting is to estimate the accuracy of the models on data that was not used to train the model i.e., using cross-validation method (different CV methods - https://www.cs.cmu.edu/~schneide/tut5/node42.html)\n",
    "\n",
    "##### How?\n",
    "<img src=\"./images/cross-validation.png\" height=\"400\" width=\"500\"/>\n",
    "#### [1.2] Parameter Tuning\n",
    "##### Why? \n",
    "- Parameter options: How many trees to build? How deep should each tree be? How much extra weight will be attached to each misclassified record? \n",
    "- Tuning these parameters to get the best results from the model is often one of the most time consuming things that data scientists do.\n",
    "\n",
    "##### How?\n",
    "- However, the process can be automated.\n",
    "\n",
    "### Even better, using the 'Scikit-Learn' package, \n",
    "- merge the parameter tuning and cross validation steps into one, allowing to search for the best combination of parameters while using k-fold cross validation to verify the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.3] Training the Model\n",
    "   ##### First, define training dataset and split the training data into the three main components – \n",
    "  (i) the user IDs (we don’t want to use these for training as they are randomly generated),\n",
    "  \n",
    "  (ii) the features to use for training (X), and \n",
    "  \n",
    "  (iii) the categories we are trying to predict (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for learning model \n",
    "df_train1.set_index('id', inplace=True)\n",
    "df_train1 = pd.concat([df_train1['country_destination'], df_all1], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "- Lable Encoding for **country_destination** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "id_train = df_train1.index.values\n",
    "labels = df_train1['country_destination']\n",
    "\n",
    "# Label encoding for the categorical data eg: ...NDF -> 7, US -> 10...\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "X = df_train1.drop('country_destination', axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 70% training data and 30% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification\n",
    "- Decision Trees: http://scikit-learn.org/stable/modules/tree.html\n",
    "- DecisionTreeClassifier(): http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree \n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "## min_samples_split=50 max_depth = 5 criterion='entropy'\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "#print (prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation:\n",
    "- The scoring parameter: http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- accuracy_score: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(prediction, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classification\n",
    "- Naive Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "- GaussianNB(): http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "\n",
    "## Computing accuracy\n",
    "print (accuracy_score(prediction, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines Classification\n",
    "- Support Vector Machines: http://scikit-learn.org/stable/modules/svm.html#svm\n",
    "- SVC(): http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM \n",
    "from sklearn import svm\n",
    "clf = svm.SVC() \n",
    "# kernel=\"rbf\"\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "## Computing accuracy\n",
    "print (accuracy_score(prediction, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: \n",
    "  - k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code\n",
    "\n",
    "\n",
    "\n",
    "### End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "  - Can we use Logistic Regression for finding accuracy on Traveler dataset? If yes, what is the best accuracy you can obtain? Show with emperical analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code\n",
    "\n",
    "\n",
    "\n",
    "### End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: HW \n",
    "- Ensemble methods: http://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "- Why Ensamble methods?\n",
    "- Which are the different Ensemble methods?\n",
    "- Can Ensemble methods be adopted for both Classification and Regression Techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code\n",
    "\n",
    "\n",
    "\n",
    "### End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: HW\n",
    "- Can we use Ensemble methods on different classification techniques for finding accuracy on Traveler dataset? If yes, which combination of Ensamble method and classification technique gives best accuracy? Show with emperical analysis?\n",
    "- sklearn.ensemble: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "- Listed here as some of the Ensamble methods (not limited to):\n",
    "    - AdaBoostClassifier \n",
    "    - BaggingClassifier\n",
    "    - ExtraTreesClassifier\n",
    "    - GradientBoostingClassifier\n",
    "    - RandomForestClassifier\n",
    "    - VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code\n",
    "\n",
    "\n",
    "\n",
    "### End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: HW\n",
    "- Multiclass and multilabel algorithms: http://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code\n",
    "\n",
    "\n",
    "\n",
    "### End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 02:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.4] GridSearchCV\n",
    "\n",
    "- **Grid Search** - Used to find best combination of parameters\n",
    "- Training data is ready in **[1.3]**\n",
    "- Now, use **GridSearchCV** (http://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.GridSearchCV.html) to run the algorithm with a range of parameters\n",
    "- Next, select the **model** that has the highest cross validated score based on the chosen measure of a performance, in this case accuracy is considered (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), but there are a range of metrics (http://scikit-learn.org/stable/modules/model_evaluation.html) we could use based on our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree with GridSearchCV\n",
    "from sklearn import tree, grid_search\n",
    "parameters = {'criterion':('gini', 'entropy'), 'max_depth':[1, 3, 5, 10]}\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "clf = grid_search.GridSearchCV(dt, parameters)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "\n",
    "## Computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(prediction, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: HW \n",
    "   - Are there any other techniques to find best combination of parameters other than GridSearhCV? If yes, which are those provide examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start Code\n",
    "\n",
    "\n",
    "## End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier Parameters:\n",
    "\n",
    "- **objective [default=reg:linear]** (https://xgboost.readthedocs.io/en/latest/python/python_api.html) --> Specify the learning task and the corresponding learning objective\n",
    "  - reg:linear: linear regression\n",
    "  - reg:logistic: logistic regression\n",
    "  - binary:logistic: logistic regression for binary classification\n",
    "  - multi:softmax: set XGBoost to do multiclass classification using the softmax objective\n",
    "  - **multi:softprob'**: same as softmax, but he result contains predicted probability of each data point belonging to each class.\n",
    "\n",
    "\n",
    "- **subsample=0.5** [default=1] --> subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting.\n",
    "\n",
    "- **colsample_bytree=0.5** [default=1] --> subsample ratio of columns when constructing each tree.\n",
    "\n",
    "- **max_depth** [default=6] --> maximum depth of a tree, increase this value will make the model more complex / likely to be overfitting. \n",
    "\n",
    "- **n_estimators** --> Number of boosted trees to fit.\n",
    "\n",
    "- more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Parameters:\n",
    "- **estimator** --> object type that implements the “fit” and “predict” methods\n",
    "- **param_grid** --> list of ictionary with parameters names (string) as keys and lists of parameter settings to try as values\n",
    "- **scoring** --> specifies model evaluation type (see model evalution discussed above)\n",
    "- **verbose** --> Controls the verbosity: the higher, the more messages\n",
    "- **n_jobs** [default=1] --> Number of jobs to run in parallel\n",
    "- **iid** --> If True, the data is assumed to be identically distributed across the folds\n",
    "- **refit** [default=True] --> Refit the best estimator with the entire dataset\n",
    "- **cv** [default=3] --> cross-validation generator\n",
    "- more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import decomposition, grid_search\n",
    "\n",
    "# Grid Search - Used to find best combination of parameters\n",
    "XGB_model = xgb.XGBClassifier(objective='multi:softprob',\n",
    "                              subsample=0.5, colsample_bytree=0.5, \n",
    "                              seed=0)\n",
    "# \n",
    "param_grid = {'max_depth': [5], 'learning_rate': [0.1], \n",
    "              'n_estimators': [5]}\n",
    "#param_grid = {'max_depth': [3, 4, 5], 'learning_rate': [0.1, 0.3], 'n_estimators': [25, 50]} ##Note running this step can take a significant amount of time, might take hours as well.\n",
    "model = grid_search.GridSearchCV(estimator=XGB_model, param_grid=param_grid,\n",
    "                                 scoring='accuracy', verbose=1, n_jobs=1, \n",
    "                                 iid=True, refit=True, cv=3)\n",
    "\n",
    "#model.fit(X, y)\n",
    "model.fit(features_train, labels_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.5] Making the Predictions\n",
    "\n",
    "- Now that we have trained the model based on the best parameters\n",
    "- Final step is to use the model to make predictions for the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss\n",
    "- loss function used in (multinomial) logistic regression and extensions of it such as neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "# Make predictions\n",
    "y_pred = model.predict(features_test)\n",
    "y_pred_prob = model.predict_proba(features_test) \n",
    "\n",
    "#Print model report:\n",
    "print (\"\\nModel Report\")\n",
    "print (\"Accuracy : %.4g\" % accuracy_score(labels_test, y_pred))\n",
    "print('Log Loss: %.4g' % log_loss(labels_test, y_gb))\n",
    "#print (\"AUC Score (Train): %f\" % roc_auc_score(labels_test, y_pred_prob))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: HW \n",
    " - **RandomForest with GridSearchCV** (or best parameter and CV selection method) \n",
    " - Does this work? If no, what is best approach to use RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start Code\n",
    "\n",
    "\n",
    "# End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: HW \n",
    " - **AdaBoost with GridSearchCV** (or best parameter and CV selection method) \n",
    " - Does this work? If no, what is best approach to use AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start Code\n",
    "\n",
    "\n",
    "# End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9: HW \n",
    " - **GradientBoostClassifier with GridSearchCV** (or best parameter and CV selection method) \n",
    " - Does this work? If no, what is best approach to use GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start Code\n",
    "\n",
    "\n",
    "# End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10: HW \n",
    " - **BaggingClassifier with GridSearchCV** (or best parameter and CV selection method) \n",
    " - Does this work? If no, what is best approach to use BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 11: HW\n",
    "- Find among all which combination gives best results\n",
    "    - (a) Classification and Ensemble methods \n",
    "    - (b) Classification and Best parameter & CV selection method\n",
    "    - (c) Classification, Ensemble and Best parameter & CV selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.5.1] Extracting the testing data out of the combined dataset (df_all) we created for the cleaning and transformation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for prediction\n",
    "#df_test1.set_index('id', inplace=True)\n",
    "df_test1 = pd.merge(df_test1.loc[:,['date_first_booking']], df_all1, how='left', left_index=True, right_index=True, sort=False)\n",
    "X_test1 = df_test1.drop('date_first_booking', axis=1, inplace=False)\n",
    "X_test1 = X_test1.fillna(-1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict_proba(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge/Competion submissions\n",
    "- Finally, to find the accuracy or log_loss we need labels of test data which is usually not given in competion and need to submit *submission file* consisting of **y_pred** and any other evaluation metrics specified on challenge/competion sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12: HW - APPROACH 03\n",
    "- There might be sum bugs, fix to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset creation\n",
    "\n",
    "- For the sake of understanding the behaviour of learning models, the training dataset is split into -\n",
    "  - training set: (X_trainA, y_trainA)\n",
    "  - validation set: (X_validA, y_validA)\n",
    "  - test set: (X_testA, y_testA)\n",
    "\n",
    "### Learning architecture\n",
    "\n",
    " - First layer: 6 classifiers from scikit-learn (Support_Vector_Machines, Logistic_Regression, Random_Forest, Gradient_Boosting, Extra_Trees_Classifier, K_Nearest_Neighbors). All classifiers are used with (almost) default parameters. At this level, many other classifiers can be used. All classifiers are applied twice.\n",
    "   - Classifiers are trained on (X_train, y_train) and used to predict the class probabilities of (X_valid).\n",
    "   - Classifiers are trained on (X = (X_train + X_valid), y = (y_train + y_valid)) and used to predict the class probabilities of (X_test)\n",
    "\n",
    " - Second layer: The predictions from the previous layer on X_valid are concatenated and used to create a new training set (XV, y_valid). The predictions on X_test are concatenated to create a new test set (XT, y_test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the classifier libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dataset\n",
    " - Parameters can be changed to explore different types of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data into train and test sets.\n",
    "XA, X_testA, yA, y_testA = train_test_split(X, y, test_size=0.2, \n",
    "                                        random_state=random_state)\n",
    "    \n",
    "#Spliting train data into training and validation sets.\n",
    "X_trainA, X_validA, y_trainA, y_validA = train_test_split(XA, yA, test_size=0.25, \n",
    "                                                      random_state=random_state)\n",
    "\n",
    "print('Data shape:')\n",
    "print('X_trainA: %s, X_validA: %s, X_testA: %s \\n' %(X_trainA.shape, X_validA.shape, \n",
    "                                                     X_testA.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### First layer (individual classifiers)\n",
    "- All classifiers are applied twice:\n",
    "   - Training on (X_trainA, y_trainA) and predicting on (X_validA)\n",
    "   - Training on (XA, yA) and predicting on (X_testA)\n",
    "- You can add / remove classifiers or change parameter values to see the effect on final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "#Defining the classifiers\n",
    "clfs = {'LR'  : LogisticRegression(random_state=random_state), \n",
    "        'SVM' : SVC(probability=True, random_state=random_state), \n",
    "        'RF'  : RandomForestClassifier(n_estimators=100, n_jobs=-1, \n",
    "                                       random_state=random_state), \n",
    "        'GBM' : GradientBoostingClassifier(n_estimators=50, \n",
    "                                           random_state=random_state), \n",
    "        'ETC' : ExtraTreesClassifier(n_estimators=100, n_jobs=-1, \n",
    "                                     random_state=random_state),\n",
    "        'KNN' : KNeighborsClassifier(n_neighbors=30)}\n",
    "    \n",
    "#predictions on the validation and test sets\n",
    "p_valid = []\n",
    "p_test = []\n",
    "   \n",
    "print('Performance of individual classifiers (1st layer) on X_testA')   \n",
    "print('------------------------------------------------------------')\n",
    "   \n",
    "for nm, clf in clfs.items():\n",
    "    #First run. Training on (X_trainA, y_trainA) and predicting on X_validA.\n",
    "    clf.fit(X_trainA, y_trainA)\n",
    "    yv = clf.predict_proba(X_validA)\n",
    "    p_valid.append(yv)\n",
    "        \n",
    "    #Second run. Training on (XA, yA) and predicting on X_testA.\n",
    "    clf.fit(XA, yA)\n",
    "    yt = clf.predict_proba(X_testA)\n",
    "    p_test.append(yt)\n",
    "       \n",
    "    #Printing out the performance of the classifier\n",
    "    print('{:10s} {:2s} {:1.7f}'.format('%s: ' %(nm), 'logloss  =>', log_loss(y_testA, yt)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with sklearn LogisticRegression\n",
    " - Predictions on X_validA are used as training set (XV) and predictions on X_testA are used as test set (XT).\n",
    " - Setting the multi-class logloss as objective function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data for the 2nd layer.\n",
    "XV = np.hstack(p_valid)\n",
    "XT = np.hstack(p_test)\n",
    "\n",
    "#By default the best C parameter is obtained with a cross-validation approach, doing grid search with\n",
    "#10 values defined in a logarithmic scale between 1e-4 and 1e4.\n",
    "#Change parameters to see how they affect the final results.\n",
    "lr = LogisticRegressionCV(Cs=10, dual=False, fit_intercept=True, \n",
    "                          intercept_scaling=1.0, max_iter=25,\n",
    "                          multi_class='ovr', n_jobs=1, penalty='l2', \n",
    "                          random_state=random_state,\n",
    "                          solver='lbfgs', tol=0.0001)\n",
    "\n",
    "lr.fit(XV, y_validA)\n",
    "y_lr = lr.predict_proba(XT)\n",
    "print('{:20s} {:2s} {:1.7f}'.format('Log_Reg:', 'logloss  =>', log_loss(y_testA, y_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient boosting\n",
    "xgb = XGBClassifier(max_depth=5, learning_rate=0.1,\n",
    "                    n_estimators=10000, objective='multi:softprob', \n",
    "                    seed=random_state)\n",
    "xgb.fit(XV, y_validA, early_stopping_rounds=15, verbose=False)\n",
    "xgb.n_estimators = xgb.best_iteration\n",
    "xgb.fit(XV, y_validA)\n",
    "y_gb = xgb.predict_proba(XT)\n",
    "print('{:20s} {:2s} {:1.7f}'.format('XGB_Reg:', 'logloss  =>', log_loss(y_testA, y_gb)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
